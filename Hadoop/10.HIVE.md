## HIVE

- 하이브는 HiveQL이라는 SQL문과 매우 유사한 언어를 제공
- 대부분의 기능은 SQL과 유사하지만 다음과 같은 차이점이 있음
  - 하이브에서 사용하는 데이터가 HDFS에 저장되는데, HDFS가 한 번 저장한 파일은 수정할 수 없기 때문에 UPDATE와 DELETE를 사용할 수 없다
  - 같은 이유로 INSERT도 비어 있는 테이블에 입력하거나, 이미 입력된 데이터를 overwrite 하는 경우만 가능하다. 그래서 하이브는 INSERT OVERWRITE라는 키워드를 사용한다
  - SQL은 어떠한 절에서도 서브쿼리를 사용할 수 있지만 HiveQL은 FROM절 에서만 서브 쿼리를 사용할 수 있다
  - SQL의 뷰는 업데이터할 수 있고, 구체화된 뷰 또는 인라인 뷰를 지원한다. 하지만 HiveQL의 뷰는 읽기 전용이며 인라인 뷰는 지원하지 않는다.
  - SELECT 문을 사용할 때 HAVING 절을 사용할 수 없다.
  - 저장 프로시저를 지원하지 않는다. 대신 맵리듀스 스크립트를 실행할 수 있다.

### 1. MySQL Coummunity Downloads

1. https://dev.mysql.com/downloads/ 에서 해당 OS 맞게 다운로드
   - CentOS이기 때문에 MySQL YUM Repositroy 다운로드
2. 다운로드 받은 파일 /usr/local/로 이동
   - /usr/local 이기 때문에 관리자 권한으로 실행

```shell
su -
cd /usr/local
cp /mnt/share/download/mysql80-community-release-el7-3.noarch.rpm .
```

3. 다운로드 받은 파일 압축 풀기 위해 gpgcheck=0 으로 설정
   - 전자서명 검사를 사용하지 않게 하기 위함

```shell
vi /etc/yum.conf
```

```shell
[main]
...
...
...
gpgcheck=0
...
...
...
```

4. rpm 설치

```shell
rpm -ivh mysql80-community-release-el7-3.noarch.rpm
```

5. mysql-server 설치

```shell
yum install -y mysql-server
```

6. gpgcheck=1로 원상 복귀

```shell
vi /etc/yum.conf
```

```shell
[main]
...
...
...
gpgcheck=1
...
...
...
```

7. MySQL 시작 프로그램 설정 및 실행

```shell
systemctl enable mysqld
```

```shell
systemctl start mysqld
```

- mysqld를 시작 프로그램으로 설정 했기 때문에 앞으로는 start mysqld를 하지 않아도 됨

8. root의 임시 비밀번호 확인
   - 2020-08-25T06:49:27.468916Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: /?GTISezz9vG를 통해 알 수 있음

```shell
cat /var/log/mysqld.log
```

```log
2020-08-25T06:49:22.738411Z 0 [System] [MY-013169] [Server] /usr/sbin/mysqld (mysqld 8.0.21) initializing of server in progress as process 21488
2020-08-25T06:49:22.749595Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.
2020-08-25T06:49:24.883785Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.
2020-08-25T06:49:27.468916Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: /?GTISezz9vG
2020-08-25T06:49:32.654415Z 0 [System] [MY-010116] [Server] /usr/sbin/mysqld (mysqld 8.0.21) starting as process 21534
2020-08-25T06:49:32.672474Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.
2020-08-25T06:49:33.560829Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.
2020-08-25T06:49:33.714396Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Bind-address: '::' port: 33060, socket: /var/run/mysqld/mysqlx.sock
2020-08-25T06:49:34.030539Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.
2020-08-25T06:49:34.030877Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.
2020-08-25T06:49:34.058816Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.0.21'  socket: '/var/lib/mysql/mysql.sock'  port: 3306  MySQL Community Server - GPL.
```

9. mysql 접속

```shell
mysql -u root -p
```

10. 비밀번호 변경
    - 임시 비밀번호 'Thisishadoop10!'으로 변경

```mysql
> alter user 'root'@'localhost' identified by 'Thisishadoop10!';
```

- validate 변경
  - 편리한 비밀번호 '1234'를 쓰기위해
  - 정책 변경은 다시 접속시 원래대로 돌아감

```mysql
> show variables like 'validate_password%';
```

```mysql
> set GLOBAL validate_password.length=4;
> set GLOBAL validate_password.mixed_case_count=0;
> set GLOBAL validate_password.policy=LOW;
> set GLOBAL validate_password.special_char_count=0;
> alter user 'root'@'localhost' identified by '1234';
```

11. Database 생성
    - Hive용 메타데이터 정보를 저장할 데이터베이스

```mysql
> create database hive_db default character set utf8;
```

12. root 권한 설정
    - 초기 root에는 권한을 부여할 권한이 있지 않기 때문에 설정해줘야 함

```shell
# mysql 8 버전부터는 root user를 생성 후 권한을 줘야함
> create user 'root'@'%' identified by '1234';
> grant all privileges on *.* to 'root'@'%' with grant option;
> flush privileges;
```

13. User 생성 후 권한 부여
    - hive_db에 대한 모든 권한을 hiveuser에 부여

```mysql
> create user 'hiveuser'@'%' identified by '1234';
> grant all privileges on hive_db.* to hiveuser@'%';
```

### 2. Hive Downloads

- http://mirror.apache-kr.org/hive/에서 하둡과 맞는 버전 확인

1. apache-hive-2.3.7-bin.tar.gz 다운로드

```shell
# 홈디렉토리에서 작업
cd
wget http://mirror.apache-kr.org/hive/hive-2.3.7/apache-hive-2.3.7-bin.tar.gz
```

2. 압축 풀기

```shell
tar -zxvf apache-hive-2.3.7-bin.tar.gz
rm -f apache-hive-2.3.7-bin.tar.gz
```

### 3. Hive 설정

1. hive에 필요한 파일 위치 (conf)

```shell
cd apache-hive-2.3.7-bin/
ls -l conf
```

2. hive-env.sh
   - HADOOP_HOME 경로 설정

```shell
mv conf/hive-env.sh.template conf/hive-env.sh
vi conf/hive-env.sh
```

```sh
# conf/hive-env.sh
...
...

# Set HADOOP_HOME to point to a specific hadoop install directory
HADOOP_HOME=/home/bit44/hadoop

...
...
```

3. hive-default.xml 설정
   - hive.metastore.local은 추가

| property                              | 용도                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| hive.metastore.local                  | value를 false로 설정하여 default db인 derby를 사용하지 않게 설정 |
| javax.jdo.option.ConnectionURL        | Hive에서 JDBC를 이용해 접속할 데이터베이스 URL 설정<br />/hive_db?createDatabaseIfNotExist=true는 hive_db가 없으면 만들라는 뜻 |
| javax.jdo.option.ConnectionDriverName | Database Driver Class 설정                                   |
| javax.jdo.option.ConnectionUserName   | Database User Name                                           |
| javax.jdo.option.ConnectionPassword   | User 비밀번호                                                |
| hive.cli.print.header                 | 쿼리 결과 출력 시 컬럼을 프린트 할 것인지 설정               |

```shell
mv conf/hive-default.xml.template conf/hive-site.xml
vi conf/hive-site.xml
```

```xml
...
...
<property>
    <name>hive.metastore.local</name>
    <value>false</value>
    <description>not use derby</description>
</property>

...
...

<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/hive_db?createDatabaseIfNotExist=true</value>
    <description>
      JDBC connect string for a JDBC metastore.
      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
    </description>
</property>


...
...

<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
</property>

...
...

<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hiveuser</value>
    <description>Username to use against metastore database</description>
</property>

...
...

<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>1234</value>
    <description>password to use against metastore database</description>
  </property>

 <property>
    <name>hive.cli.print.header</name>
    <value>true</value>
    <description>Whether to print the names of the columns in query output.</description>
</property>

...
...
...

<property>
    <name>system:java.io.tmpdir</name>
    <value>/tmp/bit44</value>
</property>
<property>
    <name>system:user.name</name>
    <value>${user.name}</value>
</property>

...
...
```

### 4. MySQL Connector 설치

- https://dev.mysql.com/downloads/connector/j/

- Select Operating System: Platform Independent

```shell
tar xzvf mysql-connector-java-8.0.21.tar.gz
cp mysql-connector-java-8.0.21/mysql-metadata-storage-0.9.2.jar lib
```

### 5. Hive 실행

#### 1. 하둡 실행

```shell
cd
cd hadoop
sbin/start-dfs.sh
sbin/start-yarn.sh
sbin/yarn-deamon.sh start proxyserver
sbin/mr-jobhistroy-daemon.sh start jobhistory
```

hive가 기동중에 생성되는 파일은 hdfs에서 /tmp/[사용자명] 에 저장된기 때문에 사용자명에 맞는 디렉토리를 생성해주고 777권한을 준다.

```shell
bin/hdfs dfs -mkdir /tmp/bit44
bin/hdfs dfs -chmod 777 /tmp/bit44
```

#### 2. Hive 초기화

hive 최초 실행 시 metastore를 초기화 해야 한다.

```shell
cd ../apache-hive-2.3.7-bin
bin/schematool -initSchema -dbType mysql
```

##### 2.1 Time Zone 수정

bin/schematool -initSchema -dbType mysql 실행 후 Time Zone **에러가 발생하면** 아래 과정을 실행한다.

CentOS의 Time Zone은 KST이고 MySQL Time Zone은 UTC여서 하나로 통일 한다. MySQL Time Zone을 KST로 변경

```shell
sudo vi /etc/my.conf
```

```shell
...
...

[mysqld]
default-time-zone='+9:00'
#
# Remove leading # and set to the amount of RAM for the most important data

...
...
```

```shell
sudo systemctl stop mysqld
sudo systemctl start mysqld
bin/schematool -initSchema -dbType mysql
```

#### 3. Hive 실행

```shell
bin/hive
```

#### 4. airline_delay 테이블 생성

- [하둡 항공데이터 실습2](https://github.com/jeonsanggi/TIL/blob/master/Hadoop/09.항공데이터_MapReduce_실습2.md) 를 Hive와 연관해서 사용하기 위한 테이블 생성

```hive
CREATE TABLE airline_delay(YEAR INT, MONTH INT, DAY_OF_MONTH INT, DAY_OF_WEEK INT, FL_DATE STRING, UNIQUE_CARRIER STRING, TAIL_NUM STRING, FL_NUM INT, ORIGIN_AIRPORT_ID INT, ORIGIN STRING, ORIGIN_STATE_ABR STRING, DEST_AIRPORT_ID INT, DEST STRING, DEST_STATE_ABR STRING, CRS_DEP_TIME INT, DEP_TIME INT, DEP_DELAY INT, DEP_DELAY_NEW INT, DEP_DEL15 INT, DEP_DELAY_GROUP INT, TAXI_OUT INT, WHEELS_OFF STRING, WHEELS_ON STRING, TAXI_IN INT, CRS_ARR_TIME INT, ARR_TIME INT, ARR_DELAY INT, ARR_DELAY_NEW INT, ARR_DEL15 INT, ARR_DELAY_GROUP INT, CANCELLED INT, CANCELLATION_CODE STRING, DIVERTED INT, CRS_ELAPSED_TIME INT, ACTUAL_ELAPSED_TIME INT, AIR_TIME INT, FLIGHTS INT, DISTANCE INT, DISTANCE_GROUP INT, CARRIER_DELAY STRING, WEATHER_DELAY STRING, NAS_DELAY STRING, SECURITY_DELAY STRING, LATE_AIRCRAFT_DELAY STRING)
PARTITIONED BY (delayYear INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;
```

#### 5. Hive에서 데이터 로드

- 리눅스 파일 시스템에 있는 데이터를 로드 할 때

```sql
load data local inpath '데이터 경로'
```

- 하둡 파일 시스템에 있는 데이터를 로드 할 때

```sql
load data inpath '/user/bit44/hive-data/*2002*csv' overwrite into table airline_delay partition (delayYear='2002');
```

```sql
load data inpath '/user/bit44/hive-data/*2003*csv' overwrite into table airline_delay partition (delayYear='2003');
```

#### 6. 데이터 조회

```sql
SELECT YEAR,MONTH,DAY_OF_MONTH,DAY_OF_WEEK,FL_DATE,UNIQUE_CARRIER,TAIL_NUM,FL_NUM,ORIGIN_AIRPORT_ID
FROM airline_delay
WHERE delayYear='2002'
LIMIT 20;
```

- WHERE절 없이 COUNT 했을 때 5829525개의 데이터를 확인하며 partition으로 나누었던 모든 데이터를 조회하는 것을 알수 있다.
  - /user/hive/warehouse/airline_delay/delayyear=2002
  - /user/hive/warehouse/airline_delay/delayyear=2003

```sql
SELECT count(*)
FROM airline_delay;
```

- WHERE절에 delayYear='2002' 했을 때 2620287개의 데이터를 확인 할 수 있다.

```sql
SELECT count(*)
FROM airline_delay
WHERE delayYear='2002';
```

- WHERE절에 delayYear='2003' 했을 때 3209238개의 데이터를 확인 할 수 있다.

```sql
SELECT count(*)
FROM airline_delay
WHERE delayYear='2003';
```

- 년월별 arrive_delay count
  - 도착 지연 수

```sql
SELECT year, month, COUNT(*) AS arrive_delay_count
FROM airline_delay
WHERE ARR_DELAY > 0
GROUP BY year, month;
```

- 평균 도착 지연

```sql
SELECT year, month, AVG(arr_delay) as avg_arrival_delay, AVG(dep_delay) as avg_departure_delay
FROM airline_delay
WHERE arr_delay > 0
GROUP BY year, month;
```

- JOIN

```sql
CREATE TABLE carrier_code(Code STRING, Description STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;
```

```sql
load data local inpath '/mnt/share/download/carriers.csv' into table carrier_code;
```

```sql
SELECT * 
FROM carrier_code 
limit 20;
```

```sql
SELECT a.year, a.UNIQUE_CARRIER, b.Description, count(*)
from airline_delay a join carrier_code b
on a.UNIQUE_CARRIER = b.code
where a.arr_delay > 0
group by a.year, a.UNIQUE_CARRIER, b.Description;
```

