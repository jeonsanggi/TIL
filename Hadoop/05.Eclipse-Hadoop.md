## Eclipse Hadoop

### 1.Maven Project 생성

- File - New - Other... - Maven - Maven Project

### 2. build & dependecies 추가

[Maven Repository](https://mvnrepository.com/)에서 의존성 정보를 알 수 있다. maven은 build하면 target 폴더에 jar 파일을 만들어 줌

- hadoop-common
- hadoop-mapreduce-client-core : client에서 mapreduce 작업을 할 수 있게 해줌

```xml
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>com.jremind</groupId>
  <artifactId>com.jremind</artifactId>
  <version>0.0.1</version>
  
  <build>
  	<plugins>
  		<plugin>
  			<groupId>org.apache.maven.plugins</groupId>
  			<artifactId>maven-compiler-plugin</artifactId>
  			<version>3.6.1</version>
  			<configuration>
  				<source>1.8</source>
  				<target>1.8</target>
  			</configuration>
  		</plugin>
  	</plugins>
  </build>
  
  <dependencies>
  	<!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common -->
	<dependency>
	    <groupId>org.apache.hadoop</groupId>
	    <artifactId>hadoop-common</artifactId>
	    <version>2.7.2</version>
	</dependency>
	<!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-core -->
	<dependency>
	    <groupId>org.apache.hadoop</groupId>
	    <artifactId>hadoop-mapreduce-client-core</artifactId>
	    <version>2.7.2</version>
	</dependency>
  </dependencies>
</project>
```



### 3. WordCount MapReduce 구현

Github 코드 : https://github.com/jeonsanggi/TIL/tree/master/Hadoop/com.jremind

#### 1. 디렉토리 구조

![image-20200820135727928](https://github.com/jeonsanggi/TIL/blob/master/Image/Hadoop/디렉토리구조.png)

#### 2. WordCountMapper.java

```java
package com.jremind.map;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends 
	Mapper<LongWritable, Text, Text, IntWritable>{
	
	// IntWritable는 하둡에서 제공하는 데이터타입이다. IntWritable으로  Serialize를 제공한다.
	private final static IntWritable one = new IntWritable(1);
	private Text word = new Text();
	
	@Override
	protected void map(LongWritable key, Text value, 
			Mapper<LongWritable, Text, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {
		
		StringTokenizer strToken = new StringTokenizer(value.toString());
		while (strToken.hasMoreTokens()) {
			word.set(strToken.nextToken());
			context.write(word, one);
		}
	}
}
```

#### 3. WordCountReducer.java

```java
package com.jremind.reduce;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class WordCountReducer extends 
	Reducer<Text, IntWritable, Text, IntWritable>{
	
	private IntWritable result = new IntWritable();

	@Override
	protected void reduce(Text key, Iterable<IntWritable> values,
			Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
		// TODO Auto-generated method stub
		int sum = 0;
		for(IntWritable value : values) {
			sum += value.get();
		}
		
		result.set(sum);
		context.write(key, result);
	}
}
```

#### 4. WordCount.java

```java
package com.jremind.driver;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

import com.jremind.map.WordCountMapper;
import com.jremind.reduce.WordCountReducer;


public class WordCount {
	public static void main(String[] args) throws Exception{
		// Configuration Job을 생성할때 Job이 필요한 요소들을 저장할 때 필요한 것들을 저쟁해놓음
		Configuration conf = new Configuration();
		
		if (args.length != 2) {
			System.out.println("Usage: WordCount <input> <output>");
			System.exit(2);
		}
		
		// 싱글턴 패턴
		Job job = Job.getInstance(conf, "WordCount");
		
		job.setJarByClass(WordCount.class);				// main으로 들어가는 클래스
		job.setMapperClass(WordCountMapper.class); 	// mapper로 들어가는 클래스
		job.setReducerClass(WordCountReducer.class); 	// Reduce로 들어가는 클래스
		
		job.setInputFormatClass(TextInputFormat.class);	 // 텍스트 인풋
		job.setOutputFormatClass(TextOutputFormat.class);// 텍스트 인풋
		
		job.setOutputKeyClass(Text.class);			// output key 클래스는 Text
		job.setOutputValueClass(IntWritable.class); // output value 클래스는 숫자

		FileInputFormat.addInputPath(job, new Path(args[0]));
		FileOutputFormat.setOutputPath(job, new Path(args[1]));
		
		job.waitForCompletion(true);
	}
}
```

#### 5. Maven build

- Run As - maven build... - Goals: clean install - Run

- build시 아래와 같은 에러 발생 시 pom.xml에 property 추가
  - Source option 5 is no longer supported. Use 6 or later
  - Target option 1.5 is no longer supported. Use 1.6 or later

```xml
...
...
...
  <dependencies>
  ...
  ...
  </dependencies>
  <properties>
      <maven.compiler.source>1.8</maven.compiler.source>
      <maven.compiler.target>1.8</maven.compiler.target>
  </properties>
</project>
```

